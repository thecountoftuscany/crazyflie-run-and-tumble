#+Title: Run and tumble + Obstacle Avoidance on the Crazyflie nano-drone
#+Author: Nishant Elkunchwar, Krishna Balasubramanian, Jessica Noe

* Introduction

This repository contains the source code for the bio-inspired light source seeking run and tumble + obstacle avoidance behaviour we designed and implemented on the Crazyflie nano-drone as a part of the course project for the course Biology Inspired Robotics at the University of Washington.

*Major highlights*:
- a deck driver for the crazyflie for the BH1750 light sensor 
- the final algorithm implemented for the crazyflie ([[https://www.youtube.com/watch?v=fgn8WjtvQ8k][video here]])
- a simulation environment for designing and testing the algorithm ([[https://www.youtube.com/watch?v=8yBKAacOlP4][video here]])
- a keyboard input publisher and a controller script to control the crazyflie's motion according to the keyboard input

The following components were added to the crazyflie:
- the FlowDeck from Bitcraze, which is an optic flow sensor combined with a time of flight sensor
- the multiranger deck from Bitcraze, which is a laser range finder in 5 directions (left, front, right, back, top)
- a BH1750 light intensity sensor mounted on a prototyping deck

The crazyflie with all of the components:
[[./resources/bcrazy.jpg]]

The contents of the repository are described below:
- ~.config~ contains the logging configurations so that sensor data from the crazyflie can be accessed using [[https://github.com/JGSuw/rospy_crazyflie][rospy_crazyflie]] and also using [[https://github.com/bitcraze/crazyflie-clients-python][cfclient]]
- ~catkin_ws~ contains the three custom ROS message types created to publish light intensity, multiranger distances and action state of the crazyflie (1 for run, 2 for tumble, 3 for obstacle avoidance)
- ~crazyflie-firmware~ contains only the additions we made to the original [[https://github.com/bitcraze/crazyflie-firmware][crazyflie-firmware]] - which is a deck driver for the BH1750 light sensor. If you are not using the continuous high resolution mode on the BH1750 sensor, please refer to the sensor datasheet and change the ~conv_factor~, ~CONT_HI_RES_MODE~ in ~i2cdevWriteByte()~ and delay time in ~vTaskDelayUntil()~ accordingly.
- ~documents~ contains the project pre-proposal and final poster
- ~resources~ contains the images used in this readme
- ~scripts~ contains the following Python scripts:
  - ~cfController.py~ - controls the crazyflie motion using keyboard input published by ~keyinputPublisher.py~
  - ~intensityPlotter.py~ - plots the x,y position of the crazyflie on the x,y axes and the detected light intensity on the z axis using ~matplotlib~. The colour of the plot denotes the current action being performed by the crazyflie - green for run, blue for tumble, and red for obstacle avoidance
  - ~keyinputPublisher.py~ - publishes keyboard input to a ROS topic which can be used by another subscriber to control the crazyflie
  - ~run-and-tumble-alg.py~ - run on an external computer, this script sends the control commands to the crazyflie based on sensor data published on local rostopics by ~sensorPublisher.py~
  - ~sensorPublisher.py~ - publishes crazyflie position, current detected light intensity and distances to obstacles in four directions (left, front, right, front) of the crazyflie. Needs ~default.launch~ from ~rospy_crazyflie~ to be running and the crazyflie dongle plugged in. (Also, add the crazyflie address to ~rospy_crazyflie/config/config.yaml~)
  - ~simulation.py~ - runs the algorithm in a [[https://pygame.org][PyGame]] simulation

* Method

** Light source characterisation
The crazyflie was first controlled from the keyboard and flown in the arena in a closely packed trajectory to capture the light intensity distribution from the light source (the path can be seen [[./resources/intensity_path.png][here]]). The plot below shows the light intensity distribution (on the z axis) vs the x,y position of the crazyflie (on the x,y axes) inside the testing arena:
[[./resources/intensity_ortho.png]]

As we can see, the intensity variation in both the x and the y axes varies roughly as inverse square distance (as expected from a non-extended, ideal light source). Also see the variation in intensity [[./resources/intensity_x.png][in the axis along the direction towards the light source]] and [[./resources/intensity_y.png][in the transverse axis]]. Hence a constant/r^2 variation was modeled in the simulation.

** Simulation
We used ~PyGame~ to create the simulation environment to for rapid testing of the algorithm before deploying it on the actual drone. The code in [[./scripts/simulation.py][simulation.py]] is pretty self-explanatory to understand what is going on.

** Algorithm
The algorithm is implemented as the following finite state machine:
[[./resources/FSM.png]]

The exact implementation details can be seen in [[./scripts/run-and-tumble-alg.py][run-and-tumble-alg.py]].

*Note*: The last intensity is taken to be the average of last 10 recorded intensity values to get rid of sensor noise.

* Further details
Please refer to [[./documents/Project-Final_Poster.pdf][the poster for the project]] for more details. In case further information is required, please contact one of the authors listed below.

* Authors

- Nishant Elkunchwar
- Krishna Balasubramanian
- Jessica Noe

* Acknowledgements

Thanks to [[https://faculty.washington.edu/minster/][professor Sawyer Fuller]] and Melanie Anderson for access to hardware, examples of software and advice.
