#+Title: Run and tumble + Obstacle Avoidance on the Crazyflie nano-drone
#+Author: Nishant Elkunchwar, Krishna Balasubramanian, Jessica Noe

* Introduction

This repository contains the source code for the bio-inspired light source seeking run and tumble + obstacle avoidance behaviour we designed and implemented on the Crazyflie nano-drone as a part of the course project for the course Biology Inspired Robotics at the University of Washington.

*Major highlights*:
- a deck driver for the crazyflie for the BH1750 light sensor 
- the final algorithm implemented for the crazyflie ([[https://www.youtube.com/watch?v=fgn8WjtvQ8k][video here]])
- a simulation environment for designing and testing the algorithm ([[https://www.youtube.com/watch?v=8yBKAacOlP4][video here]])
- a keyboard input publisher and a controller script to control the crazyflie's motion according to the keyboard input

The following components were added to the crazyflie:
- the FlowDeck from Bitcraze, which is an optic flow sensor combined with a time of flight sensor
- the multiranger deck from Bitcraze, which is a laser range finder in 5 directions (left, front, right, back, top)
- a BH1750 light intensity sensor mounted on a prototyping deck

The crazyflie with all of the components:
[[./resources/bcrazy.jpg]]

The contents of the repository are described below:
- ~.config~ contains the logging configurations so that sensor data from the crazyflie can be accessed using [[https://github.com/JGSuw/rospy_crazyflie][rospy_crazyflie]] and also using [[https://github.com/bitcraze/crazyflie-clients-python][cfclient]]
- ~catkin_ws~ contains the three custom ROS message types created to publish light intensity, multiranger distances and action state of the crazyflie (1 for run, 2 for tumble, 3 for obstacle avoidance)
- ~crazyflie-firmware~ contains only the additions we made to the original [[https://github.com/bitcraze/crazyflie-firmware][crazyflie-firmware]] - which is a deck driver for the BH1750 light sensor. If you are not using the continuous high resolution mode on the BH1750 sensor, please refer to the sensor datasheet and change the ~conv_factor~, ~CONT_HI_RES_MODE~ in ~i2cdevWriteByte()~ and delay time in ~vTaskDelayUntil()~ accordingly.
- ~documents~ contains the project pre-proposal and final poster
- ~resources~ contains the images used in this readme
- ~scripts~ contains the following Python scripts:
  - ~cfController.py~ - controls the crazyflie motion using keyboard input published by ~keyinputPublisher.py~
  - ~intensityPlotter.py~ - plots the x,y position of the crazyflie on the x,y axes and the detected light intensity on the z axis using ~matplotlib~. The colour of the plot denotes the current action being performed by the crazyflie - green for run, blue for tumble, and red for obstacle avoidance
  - ~keyinputPublisher.py~ - publishes keyboard input to a ROS topic which can be used by another subscriber to control the crazyflie
  - ~run-and-tumble-alg.py~ - run on an external computer, this script sends the control commands to the crazyflie based on sensor data published on local rostopics by ~sensorPublisher.py~
  - ~sensorPublisher.py~ - publishes crazyflie position, current detected light intensity and distances to obstacles in four directions (left, front, right, front) of the crazyflie. Needs ~default.launch~ from ~rospy_crazyflie~ to be running and the crazyflie dongle plugged in. (Also, add the crazyflie address to ~rospy_crazyflie/config/config.yaml~)
  - ~simulation.py~ - runs the algorithm in a [[https://pygame.org][PyGame]] simulation

* Instructions to run scripts and reproduce results

** Running the algorithm in simulation
- Install =numpy= and =pygame= using =pip= or =conda= or any other preferred method.
- Run =python ./scripts/simulation.py= to run a simulation with randomly placed obstacles. Change the =seed= from 0 to some other value (or remove the =random.seed()= call) at the beginning of the script to change the obstacle placement within the environment.
On running, the script also generates a =rollout_s_seed_date_time.npz= file in =../data/= that contains the trajectory information which can later be used with =./scripts/plotting.py= to generate trajectory plots or distance-vs-time plots as in the paper.
- (Optional) Edit the =fnames= list in =./scripts/plotting.py= to contain the =.npz= files whose trajectories have to be plotted. The files to reproduce the results in the submitted paper have already been included. Then run =python plotting.py= (after changing directories). This first shows the distance-vs-time plot for the simluated trajectories in the paper, then a plot of the corresponding trajectories in the simulated environment and then the plot of the actual drone trajectory as shown in the paper. Edit the =bag_no= variable to get plots for each of the three recorded experiment trials.

** Running the algorithm on the drone
*** Installations and setup required
- Follow the instructions [[https://github.com/bitcraze/crazyflie-firmware][here]] to get the default crazyflie firmware.
- Patch the default firmware with the contents from =./crazyflie-firmware= and run =make=
- Flash the modified firmware on to the drone by running the =make cload= recipe with the bluetooth USB dongle plugged in
- Install a ROS distribution for your operating system (instructions [[http://wiki.ros.org/ROS/Installation][here]])
- Install =rospy_crazyflie= (instructions [[https://github.com/JGSuw/rospy_crazyflie][here]]) and =crazyflie-lib-python= (instructions [[https://github.com/bitcraze/crazyflie-lib-python][here]])
- Add the contents of =./catkin_ws/src/rospy_crazyflie= directory to =/path_to_your_catkin_ws/src/rospy_crazyflie= and run =catkin_make=
- (Optional) Install =crazyflie-clients-python= (instructions [[https://github.com/bitcraze/crazyflie-clients-python][here]]) to get =cfclient=
- Place the contents of the =./.config= directory in your =$HOME/.config= or =$XDG_CONFIG_HOME=

*** Running the algorithm
- Turn on the drone with the flowdeck and multiranger deck added. Also make sure that the BH1750 light sensor is connected to the power, ground and I2C pins on the drone
- Add your crazyflie's =link_uri= (can be found using =cfclient=, for example) to =$HOME/.config/cfclient/config.json=
- Run =roslaunch rospy_crazyflie default.launch= to connect to the crazyflie. Make sure the terminal output shows that the drone has connected
- Change directory using =cd ./scripts=
- Run =python sensorPublisher.py= to have sensor values published to rostopics
- (Optional) Run =python keyinputPublisher.py= and then =python cfController.py= to move the crazyflie using WASD keyboard input for testing. The 'z' key triggers landing
- (Optional) run =python intensityPlotter.py= to live plot the drone's position and intensity on a 3D plot
- If the =cfController.py= script was used to manually control the drone, make sure that the =cfController= process has been killed before moving on. Run =python run-and-tumble-alg.py= to execute the algorithm

* Method

** Light source characterisation
The crazyflie was first controlled from the keyboard and flown in the arena in a closely packed trajectory to capture the light intensity distribution from the light source (the path can be seen [[./resources/intensity_path.png][here]]). The plot below shows the light intensity distribution (on the z axis) vs the x,y position of the crazyflie (on the x,y axes) inside the testing arena:
[[./resources/intensity_ortho.png]]

As we can see, the intensity variation in both the x and the y axes varies roughly as inverse square distance (as expected from a non-extended, ideal light source). Also see the variation in intensity [[./resources/intensity_x.png][in the axis along the direction towards the light source]] and [[./resources/intensity_y.png][in the transverse axis]]. Hence a constant/r^2 variation was modeled in the simulation.

** Simulation
We used ~PyGame~ to create the simulation environment to for rapid testing of the algorithm before deploying it on the actual drone. The code in [[./scripts/simulation.py][simulation.py]] is pretty self-explanatory to understand what is going on.

** Algorithm
The algorithm is implemented as the following finite state machine:
[[./resources/FSM.png]]

The exact implementation details can be seen in [[./scripts/run-and-tumble-alg.py][run-and-tumble-alg.py]].

*Note*: The last intensity is taken to be the average of last 10 recorded intensity values to get rid of sensor noise.

* Further details
Please refer to [[./documents/Project-Final_Poster.pdf][the poster for the project]] for more details. In case further information is required, please contact one of the authors listed below.

* Authors

- Nishant Elkunchwar
- Krishna Balasubramanian
- Jessica Noe

* Acknowledgements

Thanks to [[https://faculty.washington.edu/minster/][professor Sawyer Fuller]] and Melanie Anderson for access to hardware, examples of software and advice.
